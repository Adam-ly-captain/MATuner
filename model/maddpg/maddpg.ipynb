{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3539,  0.7354,  0.7557,  0.8870, -0.7074,  0.5391, -0.9963,  0.0446,\n",
      "        -0.9994,  0.9188,  0.9879])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 给定的 tensor\n",
    "tensor = torch.tensor([[-3.5387e-01,  5.0517e-02,  6.7984e-02, -9.3771e-01,  2.2663e-01],\n",
    "                       [ 7.3542e-01,  3.1036e-01,  8.1618e-02, -6.2138e-06,  9.8852e-01], \n",
    "                       [ 7.5572e-01, -9.9732e-01, -7.9426e-01,  8.8836e-01, -8.3366e-02], \n",
    "                       [ 8.8700e-01,  2.0227e-01,  3.3193e-01, -9.6707e-01,  9.8730e-01], \n",
    "                       [-7.0735e-01, -9.7488e-01,  9.9919e-01,  9.9119e-01,  9.9997e-01], \n",
    "                       [ 5.3911e-01,  2.3677e-01,  3.4878e-01,  9.4045e-01, -9.5591e-01], \n",
    "                       [-9.9628e-01, -9.2693e-01,  9.9733e-01,  8.0266e-01, -2.0433e-01], \n",
    "                       [ 4.4628e-02,  2.1111e-01,  2.5465e-01, -9.4138e-01, -9.7344e-01], \n",
    "                       [-9.9936e-01,  5.0577e-01, -9.3955e-01,  9.7298e-01, -7.4259e-01], \n",
    "                       [ 9.1880e-01,  9.8046e-01, -9.8288e-01, -8.2905e-01, -9.2763e-01], \n",
    "                       [ 9.8788e-01, -9.9778e-01,  7.3874e-01, -9.7750e-01,  8.6473e-01]])\n",
    "\n",
    "# 获取前两个 action\n",
    "first_two_actions = tensor[:, 0]\n",
    "print(first_two_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9477,  0.0251,  1.0918, -0.2259, -1.2759]])\n",
      "Processed continuous parameter: 2.2640464305877686\n",
      "Processed discrete parameter: 2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def process_continuous_output(output, min_val, max_val):\n",
    "    scaled_output = torch.tanh(output)  # 缩放到[-1, 1]范围内\n",
    "    scaled_output = 0.5 * (scaled_output + 1)  # 缩放到[0, 1]范围内\n",
    "    parameter_value = min_val + (max_val - min_val) * scaled_output  # 缩放到[min_val, max_val]范围内\n",
    "    return parameter_value\n",
    "\n",
    "def process_discrete_output(output, num_values):\n",
    "    probabilities = F.softmax(output, dim=-1)  # 转换为概率分布\n",
    "    sampled_index = torch.multinomial(probabilities, 1)  # 从概率分布中采样一个值\n",
    "    parameter_value = sampled_index.float()  # 将索引转换为浮点数\n",
    "    return parameter_value\n",
    "\n",
    "# 示例参数\n",
    "min_val = 0\n",
    "max_val = 10\n",
    "num_values = 5\n",
    "\n",
    "# 示例输出\n",
    "continuous_output = torch.randn(1)\n",
    "discrete_output = torch.randn(1, num_values)\n",
    "print(discrete_output)\n",
    "\n",
    "# 处理连续参数\n",
    "processed_continuous_parameter = process_continuous_output(continuous_output, min_val, max_val)\n",
    "print(\"Processed continuous parameter:\", processed_continuous_parameter.item())\n",
    "\n",
    "# 处理离散参数\n",
    "processed_discrete_parameter = process_discrete_output(discrete_output, num_values)\n",
    "print(\"Processed discrete parameter:\", processed_discrete_parameter.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换后的张量维度： torch.Size([1, 5])\n",
      "tensor([[1, 2, 3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设 input_data 是一个一维数组\n",
    "input_data = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# 使用 unsqueeze 将一维数组转换为二维张量\n",
    "input_data_2d = input_data.unsqueeze(0)  # 在第一个维度上增加一个维度\n",
    "\n",
    "# 检查转换后的张量维度\n",
    "print(\"转换后的张量维度：\", input_data_2d.size())\n",
    "\n",
    "# 现在你可以将 input_data_2d 作为输入传递给 PyTorch 函数了\n",
    "print(input_data_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2,3]]\n",
    "torch.tensor(a).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = a\n",
    "a = [23]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-11 22:44:17\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 获取当前日期和时间\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# 将日期和时间格式化为 'yyyy-mm-dd hh:mm:ss' 格式的字符串\n",
    "formatted_datetime = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(formatted_datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设你有一个形状为 (1, 74) 的张量 tensor\n",
    "# tensor = torch.randn(1, 74)\n",
    "# tensor1 = torch.randn(1, 74)\n",
    "# [tensor, tensor1]\n",
    "\n",
    "# 通过复制tensor的第一个维度来创建一个新的张量\n",
    "# new_tensor = tensor.expand(2, 74)\n",
    "# new_tensor[0]\n",
    "\n",
    "tensor = [1, 2, 3]\n",
    "tensor = torch.tensor(tensor).unsqueeze(0).expand(2, -1)\n",
    "tensor[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>t</th>\n",
       "      <th>reward</th>\n",
       "      <th>buffersize</th>\n",
       "      <th>criticloss</th>\n",
       "      <th>actorloss</th>\n",
       "      <th>perf_tps</th>\n",
       "      <th>perf_qps</th>\n",
       "      <th>perf_lat</th>\n",
       "      <th>perf_start_tps</th>\n",
       "      <th>perf_start_qps</th>\n",
       "      <th>perf_start_lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  episode  t reward buffersize criticloss actorloss perf_tps perf_qps  \\\n",
       "0       1  1      1          1        NaN       NaN      NaN      NaN   \n",
       "\n",
       "  perf_lat perf_start_tps perf_start_qps perf_start_lat  \n",
       "0      NaN            NaN            NaN            NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "episode_data = pd.read_excel('./res/res.xlsx')\n",
    "\n",
    "episode_data = pd.concat(\n",
    "                    [\n",
    "                        episode_data,\n",
    "                        pd.DataFrame(\n",
    "                            {\n",
    "                                \"episode\": [1],\n",
    "                                \"t\": [1],\n",
    "                                \"reward\": [1],\n",
    "                                \"buffersize\": [1],\n",
    "                            }\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "episode_data\n",
    "\n",
    "episode_data.to_excel('./res/res.xlsx', index=False)\n",
    "\n",
    "episode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [-1,1,2,3]\n",
    "a[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adaptive_hash_searches', 0),\n",
       " ('adaptive_hash_searches_btree', 7602),\n",
       " ('buffer_data_reads', 75074560),\n",
       " ('buffer_data_written', 4917248),\n",
       " ('buffer_pages_created', 143),\n",
       " ('buffer_pages_read', 4577),\n",
       " ('buffer_pages_written', 290),\n",
       " ('buffer_pool_bytes_data', 77332480),\n",
       " ('buffer_pool_bytes_dirty', 0),\n",
       " ('buffer_pool_pages_data', 4720),\n",
       " ('buffer_pool_pages_dirty', 0),\n",
       " ('buffer_pool_pages_free', 175488),\n",
       " ('buffer_pool_pages_misc', 16),\n",
       " ('buffer_pool_pages_total', 180224),\n",
       " ('buffer_pool_reads', 4578),\n",
       " ('buffer_pool_read_ahead', 0),\n",
       " ('buffer_pool_read_ahead_evicted', 0),\n",
       " ('buffer_pool_read_requests', 29427),\n",
       " ('buffer_pool_size', 2952790016),\n",
       " ('buffer_pool_wait_free', 0),\n",
       " ('buffer_pool_write_requests', 3116),\n",
       " ('dml_deletes', 0),\n",
       " ('dml_inserts', 0),\n",
       " ('dml_system_deletes', 55),\n",
       " ('dml_system_inserts', 55),\n",
       " ('dml_system_reads', 7774),\n",
       " ('dml_system_updates', 379),\n",
       " ('dml_updates', 0),\n",
       " ('file_num_open_files', 23),\n",
       " ('ibuf_merges', 0),\n",
       " ('ibuf_merges_delete', 0),\n",
       " ('ibuf_merges_delete_mark', 0),\n",
       " ('ibuf_merges_discard_delete', 0),\n",
       " ('ibuf_merges_discard_delete_mark', 0),\n",
       " ('ibuf_merges_discard_insert', 0),\n",
       " ('ibuf_merges_insert', 0),\n",
       " ('ibuf_size', 1),\n",
       " ('innodb_activity_count', 195),\n",
       " ('innodb_dblwr_pages_written', 149),\n",
       " ('innodb_dblwr_writes', 51),\n",
       " ('innodb_page_size', 16384),\n",
       " ('innodb_rwlock_sx_os_waits', 0),\n",
       " ('innodb_rwlock_sx_spin_rounds', 0),\n",
       " ('innodb_rwlock_sx_spin_waits', 0),\n",
       " ('innodb_rwlock_s_os_waits', 0),\n",
       " ('innodb_rwlock_s_spin_rounds', 0),\n",
       " ('innodb_rwlock_s_spin_waits', 0),\n",
       " ('innodb_rwlock_x_os_waits', 0),\n",
       " ('innodb_rwlock_x_spin_rounds', 0),\n",
       " ('innodb_rwlock_x_spin_waits', 0),\n",
       " ('lock_deadlocks', 0),\n",
       " ('lock_deadlock_false_positives', 0),\n",
       " ('lock_deadlock_rounds', 201),\n",
       " ('lock_rec_grant_attempts', 0),\n",
       " ('lock_rec_release_attempts', 100),\n",
       " ('lock_row_lock_current_waits', 0),\n",
       " ('lock_row_lock_time', 0),\n",
       " ('lock_row_lock_time_avg', 0),\n",
       " ('lock_row_lock_time_max', 0),\n",
       " ('lock_row_lock_waits', 0),\n",
       " ('lock_schedule_refreshes', 201),\n",
       " ('lock_threads_waiting', 0),\n",
       " ('lock_timeouts', 0),\n",
       " ('log_waits', 0),\n",
       " ('log_writes', 49),\n",
       " ('log_write_requests', 1707),\n",
       " ('os_data_fsyncs', 153),\n",
       " ('os_data_reads', 4615),\n",
       " ('os_data_writes', 428),\n",
       " ('os_log_bytes_written', 126976),\n",
       " ('os_log_fsyncs', 0),\n",
       " ('os_log_pending_fsyncs', 0),\n",
       " ('os_log_pending_writes', 0),\n",
       " ('trx_rseg_history_len', 0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "\n",
    "def get_mysql_conn(host):\n",
    "    \"\"\"\n",
    "    host: 192.168.182.103/104\n",
    "    get_state(host='192.168.182.103')\n",
    "    \"\"\"\n",
    "    # 连接到MySQL数据库\n",
    "    conn = mysql.connector.connect(\n",
    "        host=host, user=\"hadoop\", password=\"123456\", database=\"test\"\n",
    "    )\n",
    "\n",
    "    return conn\n",
    "\n",
    "\n",
    "def get_state(conn):\n",
    "    \"\"\"\n",
    "    获取74个state metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建游标对象\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # 执行SQL查询\n",
    "        # cursor.execute(\"SHOW STATUS\")\n",
    "\n",
    "        cursor.execute(\n",
    "            'SELECT NAME, COUNT from information_schema.INNODB_METRICS where status=\"enabled\" ORDER BY NAME;'\n",
    "        )\n",
    "\n",
    "        # 获取查询结果\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        # 关闭游标\n",
    "        cursor.close()\n",
    "\n",
    "\n",
    "def close_conn(conn):\n",
    "    \"\"\"\n",
    "    关闭数据库连接\n",
    "    \"\"\"\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "conn1 = get_mysql_conn(host='192.168.182.103')\n",
    "conn2 = get_mysql_conn(host='192.168.182.104')\n",
    "# get_state(conn=conn1)\n",
    "get_state(conn=conn2)\n",
    "get_state(conn=conn2)\n",
    "get_state(conn=conn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "a = [1, 2, 3]\n",
    "\n",
    "res.append(a)\n",
    "\n",
    "a = [2]\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('./res/eval_write_only.xlsx')\n",
    "\n",
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0007824897766113"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a = time.time()\n",
    "time.sleep(1)\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "b - a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
